{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30eae7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName(\"Cars\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd38ab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+--------+------+-----+\n",
      "|buying|maint|doors|persons|lug_boot|safety|class|\n",
      "+------+-----+-----+-------+--------+------+-----+\n",
      "| vhigh|vhigh|    2|      2|   small|   med|unacc|\n",
      "| vhigh|vhigh|    2|      2|   small|  high|unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|   low|unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|   med|unacc|\n",
      "| vhigh|vhigh|    2|      2|     med|  high|unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|   low|unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|   med|unacc|\n",
      "| vhigh|vhigh|    2|      2|     big|  high|unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|   low|unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|   med|unacc|\n",
      "| vhigh|vhigh|    2|      4|   small|  high|unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|   low|unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|   med|unacc|\n",
      "| vhigh|vhigh|    2|      4|     med|  high|unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|   low|unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|   med|unacc|\n",
      "| vhigh|vhigh|    2|      4|     big|  high|unacc|\n",
      "| vhigh|vhigh|    2|   more|   small|   low|unacc|\n",
      "| vhigh|vhigh|    2|   more|   small|   med|unacc|\n",
      "| vhigh|vhigh|    2|   more|   small|  high|unacc|\n",
      "+------+-----+-----+-------+--------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(r\"F:/desktop/Spark/datasets/car_evaluation.csv\",header=True,inferSchema=True).toDF(\n",
    "  'buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "666665b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- buying: string (nullable = true)\n",
      " |-- maint: string (nullable = true)\n",
      " |-- doors: string (nullable = true)\n",
      " |-- persons: string (nullable = true)\n",
      " |-- lug_boot: string (nullable = true)\n",
      " |-- safety: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "778632af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3056691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "val=['vhigh','high','low','5more','more','small','big']\n",
    "labels=['unacc','acc','good','vgood']\n",
    "att=[val,labels]\n",
    "for col in df.columns[:-1]:\n",
    "    for i in range(len(val)):\n",
    "        if val[i] in list (df.select(col).toPandas()[col]):\n",
    "            df=df.withColumn(col,regexp_replace(df[col],val[i],str(i)))\n",
    "for cols in df.columns[:-1]:\n",
    "    df=df.withColumn(cols,df[cols].cast('Integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32cfe95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- buying: integer (nullable = true)\n",
      " |-- maint: integer (nullable = true)\n",
      " |-- doors: integer (nullable = true)\n",
      " |-- persons: integer (nullable = true)\n",
      " |-- lug_boot: integer (nullable = true)\n",
      " |-- safety: integer (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "758163e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+\n",
      "|buying|maint|doors|persons|lug_boot|safety|class|buying_index|maint_index|doors_index|persons_index|lug_boot_index|safety_index|class_index|\n",
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+\n",
      "| vhigh|vhigh|    2|      2|   small|   med|unacc|         3.0|        3.0|        3.0|          2.0|           2.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|   small|  high|unacc|         3.0|        3.0|        3.0|          2.0|           2.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     med|   low|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     med|   med|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     med|  high|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     big|   low|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     big|   med|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      2|     big|  high|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|   small|   low|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|   small|   med|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|   small|  high|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     med|   low|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     med|   med|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     med|  high|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     big|   low|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     big|   med|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|      4|     big|  high|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         0.0|        0.0|\n",
      "| vhigh|vhigh|    2|   more|   small|   low|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         2.0|        0.0|\n",
      "| vhigh|vhigh|    2|   more|   small|   med|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         1.0|        0.0|\n",
      "| vhigh|vhigh|    2|   more|   small|  high|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         0.0|        0.0|\n",
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.ml.feature import StringIndexer\n",
    "#indexer=StringIndexer(inputCol='buying',outputCol='buying_index')\n",
    "#df1=indexer.fit(df).transform(df)\n",
    "#indexer=StringIndexer(inputCol='maint',outputCol='maint_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#indexer=StringIndexer(inputCol='doors',outputCol='doors_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#indexer=StringIndexer(inputCol='persons',outputCol='persons_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#indexer=StringIndexer(inputCol='lug_boot',outputCol='lug_boot_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#indexer=StringIndexer(inputCol='safety',outputCol='safety_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#indexer=StringIndexer(inputCol='class',outputCol='class_index')\n",
    "#df1=indexer.fit(df1).transform(df1)\n",
    "#df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff1e245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+--------------------+\n",
      "|buying|maint|doors|persons|lug_boot|safety|class|buying_index|maint_index|doors_index|persons_index|lug_boot_index|safety_index|class_index|            features|\n",
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+--------------------+\n",
      "| vhigh|vhigh|    2|      2|   small|   med|unacc|         3.0|        3.0|        3.0|          2.0|           2.0|         1.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|   small|  high|unacc|         3.0|        3.0|        3.0|          2.0|           2.0|         0.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     med|   low|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         2.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     med|   med|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         1.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     med|  high|unacc|         3.0|        3.0|        3.0|          2.0|           1.0|         0.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     big|   low|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         2.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     big|   med|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         1.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      2|     big|  high|unacc|         3.0|        3.0|        3.0|          2.0|           0.0|         0.0|        0.0|[3.0,3.0,3.0,2.0,...|\n",
      "| vhigh|vhigh|    2|      4|   small|   low|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         2.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|   small|   med|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         1.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|   small|  high|unacc|         3.0|        3.0|        3.0|          0.0|           2.0|         0.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     med|   low|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         2.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     med|   med|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         1.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     med|  high|unacc|         3.0|        3.0|        3.0|          0.0|           1.0|         0.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     big|   low|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         2.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     big|   med|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         1.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|      4|     big|  high|unacc|         3.0|        3.0|        3.0|          0.0|           0.0|         0.0|        0.0|[3.0,3.0,3.0,0.0,...|\n",
      "| vhigh|vhigh|    2|   more|   small|   low|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         2.0|        0.0|[3.0,3.0,3.0,1.0,...|\n",
      "| vhigh|vhigh|    2|   more|   small|   med|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         1.0|        0.0|[3.0,3.0,3.0,1.0,...|\n",
      "| vhigh|vhigh|    2|   more|   small|  high|unacc|         3.0|        3.0|        3.0|          1.0|           2.0|         0.0|        0.0|[3.0,3.0,3.0,1.0,...|\n",
      "+------+-----+-----+-------+--------+------+-----+------------+-----------+-----------+-------------+--------------+------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va=VectorAssembler(inputCols=['buying_index', 'maint_index', 'doors_index', 'persons_index', 'lug_boot_index', 'safety_index'],outputCol='features')\n",
    "output=va.transform(df1)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d557124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|            features|class_index|\n",
      "+--------------------+-----------+\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,2.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,0.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,1.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,1.0,...|        0.0|\n",
      "|[3.0,3.0,3.0,1.0,...|        0.0|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=output.select('features','class_index')\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e75b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train,test)=df1.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4762c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier(featuresCol='features',labelCol='class_index')\n",
    "clf=clf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9952028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+--------------------+--------------------+----------+\n",
      "|           features|class_index|       rawPrediction|         probability|prediction|\n",
      "+-------------------+-----------+--------------------+--------------------+----------+\n",
      "|(6,[0,1],[1.0,1.0])|        3.0| [4.0,9.0,25.0,41.0]|[0.05063291139240...|       3.0|\n",
      "|(6,[0,2],[1.0,1.0])|        3.0|[29.0,114.0,0.0,1...|[0.18954248366013...|       1.0|\n",
      "|(6,[0,3],[2.0,1.0])|        1.0|[29.0,114.0,0.0,1...|[0.18954248366013...|       1.0|\n",
      "+-------------------+-----------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=clf.transform(test)\n",
    "pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56f8b051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.8826979472140762\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "evaluator= MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='class_index',\n",
    "                                             metricName='accuracy')\n",
    "\n",
    "                                             \n",
    "acc = evaluator. evaluate(pred)\n",
    "print ('Prediction Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf1d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
